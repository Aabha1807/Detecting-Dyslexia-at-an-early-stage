{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e53a6f-7fea-4d73-bab1-b45858a19a6a",
   "metadata": {},
   "source": [
    "# Pattern Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49004c1-5352-44b0-9a51-1536de1ed311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import PIL\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb2520-5eed-4a77-bb68-b7142e1707b8",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c71601-e59f-47a6-af5f-4ad0c5804ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzklEQVR4nGNgGHCgcP21NoLHhCqZpCHigEuSLxGPqTP+//+/CIdc9P/////vwy6n//b/lT3Iksh2Ogkx9J7BYaj26//zGDr+Z2PV6SDCsBZVOSOc5bxMjIHhKrPG+TsMT4rQTZ3zHwHQdWpcZ2D40iuj4Myw8eiR42ganf//72NgYDDF5k+Wp//fi6BLwlwbKsVw8A3ERzwYOh///+nOwMDAwPDwvxCGzrUPOncyMDAwMJxkCMa0FAb6/u/ALWn9/z/cUiZM6Zk/cGulPQAAx4xLDpAJOxoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x162FCBDF0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = 'Gambo/Train'\n",
    "validation_dir = 'Gambo/Test'\n",
    "try_img = PIL.Image.open(train_dir+'/Normal/A-0.png')\n",
    "try_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ddb34d-15b1-47e4-93aa-f2a59cdafdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode of the data:  L\n",
      "Size of Images:  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mode of the data: \", try_img.mode) \n",
    "print(\"Size of Images: \", try_img._size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff57c83-308f-4871-a055-9ddebefaea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:  39334\n",
      "Reversal:  46781\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "print(\"Normal: \", len(glob.glob(train_dir+'/Normal/*')))\n",
    "print(\"Reversal: \", len(glob.glob(train_dir+'/Reversal/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de0f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /Users/Aabha/Documents/My-Doc/Aabha/Gambo/Train/Corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ddb81f-ff52-49c3-b4cd-0c3092151a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86115 images belonging to 2 classes.\n",
      "Found 37439 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = try_img._size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                    rotation_range=10,\n",
    "                                    # zoom_range = 0.1,\n",
    "                                    # width_shift_range=0.1,\n",
    "                                    # height_shift_range=0.1\n",
    "                                  )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,   \n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    class_mode ='binary')  \n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17671b63-192e-4207-8d6c-060e34175545",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "231a513b-52aa-42ee-b7a4-e3ddb29c762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 1)         28        \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 6280      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,317\n",
      "Trainable params: 6,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = IMAGE_SIZE + (3, )\n",
    "print(INPUT_SHAPE)\n",
    "\n",
    "model = tf.keras.models.Sequential([                               \n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='relu', input_shape=INPUT_SHAPE, padding=\"same\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "378bb4d5-ca75-4e45-b3c5-a23230877dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5b42c9-c120-4583-923d-1774b5ef09a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 86115//BATCH_SIZE\n",
    "VALIDATION_STEPS = 37439//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1a7632-e1de-4fd0-a1a2-13289c770541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 02:55:28.240977: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2022-06-25 02:55:28.542339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2689/2691 [============================>.] - ETA: 0s - loss: 0.4356 - accuracy: 0.7959"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 02:56:01.105271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691/2691 [==============================] - 41s 15ms/step - loss: 0.4356 - accuracy: 0.7960 - val_loss: 0.4483 - val_accuracy: 0.7960\n",
      "Epoch 2/5\n",
      "2691/2691 [==============================] - 39s 15ms/step - loss: 0.3729 - accuracy: 0.8338 - val_loss: 0.4390 - val_accuracy: 0.8065\n",
      "Epoch 3/5\n",
      "2691/2691 [==============================] - 39s 14ms/step - loss: 0.3598 - accuracy: 0.8409 - val_loss: 0.4409 - val_accuracy: 0.8058\n",
      "Epoch 4/5\n",
      "2691/2691 [==============================] - 39s 14ms/step - loss: 0.3515 - accuracy: 0.8461 - val_loss: 0.4366 - val_accuracy: 0.8077\n",
      "Epoch 5/5\n",
      "2691/2691 [==============================] - 39s 15ms/step - loss: 0.3471 - accuracy: 0.8493 - val_loss: 0.4322 - val_accuracy: 0.8116\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, \n",
    "            epochs=5,\n",
    "            steps_per_epoch = STEPS_PER_EPOCH,\n",
    "            validation_data = validation_generator,\n",
    "            validation_steps = VALIDATION_STEPS, \n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805b283-8d12-4c26-a9f9-92f2f05ef59f",
   "metadata": {},
   "source": [
    "# Testing with custom input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fa0c512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d8cebcd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try_img = PIL.Image.open(validation_dir+'/Normal/A-41.png')\n",
    "try_img\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread(validation_dir+'/Reversal/1_3.png')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "555122b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.resize(img,(28,28))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "890e426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = np.reshape(img,[1,28,28,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "689b5c46-bfda-42fe-ba47-01bd0f524864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00971901]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fcdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
